# import streamlit as st
# import pandas as pd
# import matplotlib.pyplot as plt
# import seaborn as sns

# st.set_page_config(page_title='Cardiac disease', page_icon='â¤')

# df = pd.read_csv('he.csv')

# st.header('ğŸ“ˆ ë°ì´í„° í†µê³„', divider='red')

# tab1, tab2, tab3= st.tabs(['ì‹¤ì œë°ì´í„°', 'ë°ì´í„° í†µê³„', 'ì»¬ëŸ¼ë°ì´í„°'])

# with tab1:
#     t1 = df.head(10)
#     st.write(t1)

# with tab2:
#     # td1 = df.describe()
#     # st.write(td1)
#     col = df.columns
#     scol = st.multiselect('select col', col)
#     ldf = df.loc[:, scol]
#     st.write(ldf)

# with tab3:
#     c = st.selectbox('Select column', ['age', 'a'])
#     cl = df['age'] == c
#     a_df = df.loc[cl]
#     st.write(a_df)

# -*- coding: utf-8 -*-
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
from xgboost import XGBClassifier
from sklearn.preprocessing import LabelEncoder
import streamlit as st 
import joblib #ëª¨ë¸ì €ì¥ ë¶ˆëŸ¬ì˜¬ë•Œ


st.set_page_config(page_title='Cardiac disease', page_icon='â¤')
st.sidebar.header("ë¨¸ì‹ ëŸ¬ë‹ ë³´ê³ ì„œ")



df = pd.read_csv('he.csv')

st.write(df)
y = df['DEATH_EVENT']
X= df.drop(['DEATH_EVENT'], axis=1) 
    
# ì—°ì†í˜• ì…ë ¥ ë°ì´í„°, ë²”ì£¼í˜• ì…ë ¥ ë°ì´í„°, ì¶œë ¥ ë°ì´í„°ë¡œ êµ¬ë¶„
X_num = df[['age', 'creatinine_phosphokinase','ejection_fraction', 'platelets','serum_creatinine', 'serum_sodium']]
X_cat = df[['anaemia', 'diabetes', 'high_blood_pressure', 'sex', 'smoking']]
y = df['DEATH_EVENT']

# ìˆ˜ì¹˜í˜• ì…ë ¥ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•˜ê³  ì…ë ¥ ë°ì´í„° í†µí•©í•˜ê¸°
scaler = StandardScaler()
scaler.fit(X_num)
X_scaled = scaler.transform(X_num) 
X_scaled = pd.DataFrame(data=X_scaled, index=X_num.index, columns=X_num.columns)
X = pd.concat([X_scaled, X_cat], axis=1) # í–‰ ë°©í–¥ìœ¼ë¡œ ì¡°ì¸

#í•™ìŠµ, í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)

#Logistic Regression ëª¨ë¸ ìƒì„±
model_lr = LogisticRegression(max_iter=1000) # í•™ìŠµ 1000ë²ˆ ì§„í–‰
model_lr.fit(X_train, y_train)
model_lr.score(X_test, y_test) # 0.7555555555555555

pred = model_lr.predict(X_test) # X_test ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ yê°’ ì˜ˆì¸¡

#XGBoost ëª¨ë¸ ìƒì„±
model_xgb = XGBClassifier()
model_xgb.fit(X_train, y_train)
model_xgb.score(X_test, y_test) # 0.8

#í•™ìŠµí•œ ëª¨ë¸ì„ í†µí•œ ì˜ˆì¸¡
pred = model_xgb.predict(X_test)
st.write(classification_report(y_test, pred))


fig=plt.figure(figsize=(10,4))
st.header("Feature_importancs Graph")
plt.bar(X.columns,model_xgb.feature_importances_)
plt.xticks(rotation=90)
st.pyplot(fig)


